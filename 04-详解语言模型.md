## LLM
LLM类是一个为LLM借口而设计的类。有很多LLM提供者（OpenAI、Cohere、HuggingFace等）-这个类目的是为所有这些提供者提供一个标准接口。这部分文档中，我们将猪猪与通用的LLM功能。关于使用特定LLM封装器的细节。

## 自定义LLM
自定义LLM只需要实现一个必须的东西：
- _call方法：接收一个字符串，一些可选的停止词，并返回一个字符串

一个可选的方法：
- _identifying_params属性，用来帮助打印这个类。应该返回一个字典。

下面让我们实现一个简单的LLM，它只是返回输入的前N个字符。

```
from langchain.llms.base import LLM
from typing import Optional,List,Mapping,Any

class CustomLLM(LLM):
    
    n: int
        
    @property
    def _llm_type(self) -> str:
        return "custom"
    
    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:
        if stop is not None:
            raise ValueError("stop kwargs are not permitted.")
        return prompt[:self.n]
    
    @property
    def _identifying_params(self) -> Mapping[str, Any]:
        """Get the identifying parameters."""
        return {"n": self.n}
```

## 假的LLM
我们公开了一个假的LLM类，可以用来测试。这允许你模拟对LLM的调用，并模拟如果LLM以某种方式响应会发生什么。

## LLM 序列化