对于一些简单的应用来说，孤立地使用LLM是没有问题的，但许多更复杂的应用需要将LLM串联起来--要么相互串联，要么与其他专家串联。LangChain为链子提供了一个标准的接口，以及一些常见的链子实现，以方便使用。

在这里，将学习在LangChain种创建简单的链，并向其中加入组件

## 为什么我们需要提示链呢？

链允许我们将多个组件组合在一起，创建一个单一的，连贯的应用程序，例如，我们可以创建一个链，接收用户输入,用PromptTemplate格式化，然后将格式化后的相应传送给LLM，我们可以通过多个链组合在一起。

```
from langchain.prompts import PromptTemplate
from langchain.llms import OpenAI
from langchain.chains import LLMChain

llm = OpenAI(temperature=0.9)
prompt = PromptTemplate(
    input_variables = ["producct"],
    template="What is a good name for a company that makes {product}"
)

chain = LLMChain(llm = llm,prompt=prompt)

print(chain.run("colorful socks"))
```

我们也可以使用chatModel

```
from langchain.prompts import PromptTemplate
from langchain.llms import OpenAI
from langchain.chains import LLMChain
from langchain.chat_models import ChatOpenAI
from langchain.prompts.chat import(
    ChatPromptTemplate,
    HumanMessagePromptTemplate
)

human_message_prompt = HumanMessagePromptTemplate(
    prompt = PromptTemplate(
            template="What is a good name for a company that makes {product}?",
            input_variables=["product"],
    )
)

chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])
chat = ChatOpenAI(temperature=0.9)
chain = LLMChain(llm=chat, prompt=chat_prompt_template)
print(chain.run("colorful socks"))

```

## 顺序链
我们使用顺序链实现按照预定的顺序执行。
下面，用一个例子进行说明：
- 首先为一个公式创建一个公式名称
- 然后为改产品创建一个口号

```
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.llms import OpenAI
from langchain.chains import SimpleSequentialChain

llm = OpenAI(temperature=0.9)
prompt = PromptTemplate(
    input_variables=["product"],
    template="What is a good name for a company that makes {product}?",
)
second_prompt = PromptTemplate(
    input_variables=["company_name"],
    template="Write a catchphrase for the following company: {company_name}",
)

chain = LLMChain(llm=llm, prompt=prompt)
chain_two = LLMChain(llm =llm,prompt = second_prompt)

overall_chain = SimpleSequentialChain(chains=[chain,chain_two],verbose=True)

catchprase = overall_chain.run("colorful socks")

print(catchprase)


```

### 自定义链
为了创建一个自定义链：
- 首先是继承Chain
- 然后填入input_keys和output_keys属性
- 最后添加_call方法展示如何执行chain

下面用一个例子说明：

```
from langchain.chains import LLMChain
from langchain.chains.base import Chain
from typing import Dict,List
from langchain.prompts import PromptTemplate
from langchain.llms import OpenAI
class ConcatenateChain(Chain):
    chain_1:LLMChain
    chain_2:LLMChain

    @property
    def input_keys(self) -> List[str]:
        all_input_vars = set(self.chain_1.input_keys).union(set(self.chain_2.input_keys))
        return list(all_input_vars)

    @property
    def output_keys(self) -> List[str]:
        return ['concat_output']

    def _call(self, inputs: Dict[str, str]) -> Dict[str, str]:
        output_1 = self.chain_1.run(inputs)
        output_2 = self.chain_2.run(inputs)
        return {'concat_output': output_1 + output_2}

llm = OpenAI(temperature=0.9)

prompt_1 = PromptTemplate(
    input_variables=["product"],
    template="What is a good name for a company that makes {product}?",
)
chain_1 = LLMChain(llm=llm, prompt=prompt_1)

prompt_2 = PromptTemplate(
    input_variables=["product"],
    template="What is a good slogan for a company that makes {product}?",
)
chain_2 = LLMChain(llm=llm, prompt=prompt_2)

concat_chain = ConcatenateChain(chain_1=chain_1, chain_2=chain_2)
concat_output = concat_chain.run("colorful socks")
print(f"Concatenated output:\n{concat_output}")
```

### 通用链的几个例子

#### LLM chain
```
from langchain import PromptTemplate, OpenAI, LLMChain
# 单个参数
template = """Question: {question}
Answer: Let's think step by step."""
prompt = PromptTemplate(template=template, input_variables=["question"])
llm_chain = LLMChain(prompt=prompt, llm=OpenAI(temperature=0), verbose=True)

question = "What NFL team won the Super Bowl in the year Justin Beiber was born?"

llm_chain.predict(question=question)


# 多个参数
template = """Write a {adjective} poem about {subject}."""
prompt = PromptTemplate(template=template, input_variables=["adjective", "subject"])
llm_chain = LLMChain(prompt=prompt, llm=OpenAI(temperature=0), verbose=True)

llm_chain.predict(adjective="sad", subject="ducks")

```

#### Transformation Chain

#### Sequential Chain